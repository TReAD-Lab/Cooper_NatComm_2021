{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update paths & load required packages\n",
    "path2code = '/script_dir/'\n",
    "path2data = '/data_dir/'\n",
    "path2raw = path2data + 'raw/'\n",
    "path2clean = path2data + 'clean/'\n",
    "\n",
    "import datetime, mmap, os, re, sys, decimal, glob\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "import rpy2\n",
    "from collections import defaultdict\n",
    "from scipy.stats import pearsonr \n",
    "%load_ext rpy2.ipython\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all surveys into one dataframe. Each subject has up to 6 .CSVs, 1 for every 2-hour time window (i.e. 10 AM, 12 PM).\n",
    "dfs = []\n",
    "out = pd.DataFrame\n",
    "\n",
    "files = (glob.glob(path2raw + '*.csv'))\n",
    "for file in files:\n",
    "    df = pd.read_csv(file, skiprows = [0,2])\n",
    "    df['survey_number'] = file[-5]\n",
    "    dfs.append(df)\n",
    "out = pd.DataFrame\n",
    "out = pd.concat(dfs, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull in header names and rename headers\n",
    "headers = pd.read_csv('headers.csv')\n",
    "\n",
    "old_headers = headers['original']\n",
    "new_headers = headers['new']\n",
    "rename_dict = dict(zip(old_headers, new_headers))\n",
    "\n",
    "out.rename(columns=rename_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>response_type</th>\n",
       "      <th>progress</th>\n",
       "      <th>duration</th>\n",
       "      <th>finished</th>\n",
       "      <th>recorded_date</th>\n",
       "      <th>responseID</th>\n",
       "      <th>dist_channel</th>\n",
       "      <th>language</th>\n",
       "      <th>...</th>\n",
       "      <th>anhedonia_day</th>\n",
       "      <th>down_day</th>\n",
       "      <th>stressed_day</th>\n",
       "      <th>tired_day</th>\n",
       "      <th>nervous_day</th>\n",
       "      <th>uncontrolled_worry_day</th>\n",
       "      <th>worry_day</th>\n",
       "      <th>low_high_mood_day</th>\n",
       "      <th>survey_number</th>\n",
       "      <th>sleep_quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-11-14 18:15:29</td>\n",
       "      <td>2017-11-14 18:19:44</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>254</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-11-14 18:19:44</td>\n",
       "      <td>R_2ZTsOaNZSwZMekF</td>\n",
       "      <td>anonymous</td>\n",
       "      <td>EN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-11-15 22:14:46</td>\n",
       "      <td>2017-11-15 22:36:02</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>1275</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-11-15 22:36:02</td>\n",
       "      <td>R_3rG9kxKEPs5gs60</td>\n",
       "      <td>anonymous</td>\n",
       "      <td>EN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-11-16 19:36:08</td>\n",
       "      <td>2017-11-16 19:40:28</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>260</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-11-16 19:40:28</td>\n",
       "      <td>R_4ONLvitXRz34yyt</td>\n",
       "      <td>anonymous</td>\n",
       "      <td>EN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-11-16 20:47:37</td>\n",
       "      <td>2017-11-16 20:51:21</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>224</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-11-16 20:51:21</td>\n",
       "      <td>R_3J7W9JQY4Sjiyva</td>\n",
       "      <td>anonymous</td>\n",
       "      <td>EN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-11-17 22:13:50</td>\n",
       "      <td>2017-11-17 22:17:27</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>216</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-11-17 22:17:27</td>\n",
       "      <td>R_OEakzsMQTbHmVBn</td>\n",
       "      <td>anonymous</td>\n",
       "      <td>EN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            start_date             end_date  response_type  progress  \\\n",
       "0  2017-11-14 18:15:29  2017-11-14 18:19:44              0       100   \n",
       "1  2017-11-15 22:14:46  2017-11-15 22:36:02              0       100   \n",
       "2  2017-11-16 19:36:08  2017-11-16 19:40:28              0       100   \n",
       "3  2017-11-16 20:47:37  2017-11-16 20:51:21              0       100   \n",
       "4  2017-11-17 22:13:50  2017-11-17 22:17:27              0       100   \n",
       "\n",
       "   duration  finished        recorded_date         responseID dist_channel  \\\n",
       "0       254         1  2017-11-14 18:19:44  R_2ZTsOaNZSwZMekF    anonymous   \n",
       "1      1275         1  2017-11-15 22:36:02  R_3rG9kxKEPs5gs60    anonymous   \n",
       "2       260         1  2017-11-16 19:40:28  R_4ONLvitXRz34yyt    anonymous   \n",
       "3       224         1  2017-11-16 20:51:21  R_3J7W9JQY4Sjiyva    anonymous   \n",
       "4       216         1  2017-11-17 22:17:27  R_OEakzsMQTbHmVBn    anonymous   \n",
       "\n",
       "  language      ...       anhedonia_day  down_day stressed_day  tired_day  \\\n",
       "0       EN      ...                 3.0       2.0          2.0        2.0   \n",
       "1       EN      ...                 3.0       3.0          4.0        3.0   \n",
       "2       EN      ...                 1.0       1.0          1.0        1.0   \n",
       "3       EN      ...                 1.0       1.0          2.0        1.0   \n",
       "4       EN      ...                 2.0       2.0          3.0        2.0   \n",
       "\n",
       "   nervous_day  uncontrolled_worry_day  worry_day  low_high_mood_day  \\\n",
       "0          2.0                     2.0        1.0                3.0   \n",
       "1          3.0                     3.0        3.0                3.0   \n",
       "2          1.0                     1.0        1.0                4.0   \n",
       "3          2.0                     2.0        1.0                1.0   \n",
       "4          3.0                     2.0        2.0                4.0   \n",
       "\n",
       "   survey_number  sleep_quality  \n",
       "0              6            NaN  \n",
       "1              6            NaN  \n",
       "2              6            NaN  \n",
       "3              6            NaN  \n",
       "4              6            NaN  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check headers\n",
    "out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1016,  1011,  1005,  1017,  1015,  1007,  1012,  1020,  1019,\n",
       "        1022,  1024,  1026,  1023,  1025,  1027,  1029,  1100,  1034,\n",
       "        1033,  1101,  1102,  1032,  1103,  1104,  1105,  1038,  9999,\n",
       "        1107,  1037,  1109,  1044,  1108,  1110,  1045,  1043,  1111,\n",
       "        1042,  1114,  1116,  1117,  1120,  1118,  1122,  1121,  1125,\n",
       "        1127,  1128,  1132,  1126,  1130,  1131,  1133,  1145,  1136,\n",
       "        1135,  1138,  1137,  1141,  1142,   100,   119,  1106,  1150,\n",
       "        1146,  1013,  1036,  1123,     0,  1139, 11038,  1003,  2043,\n",
       "         114,  1035,  1112, 11117])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify unique subject IDs, based on subject report\n",
    "out['subjectID'] = out.subjectID.apply(lambda x: int(str(x).replace('-','')))\n",
    "out.subjectID.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1100, 1101, 1102, 1103, 1104, 1105, 1107, 1109, 1110, 1111, 1114,\n",
       "       1116, 1117, 1118, 1120, 1122, 1121, 1125, 1127, 1128, 1126, 1130,\n",
       "       1131, 1132, 1133, 1005, 1007, 1011, 1012, 1015, 1016, 1017, 1019,\n",
       "       1020, 1022, 1023, 1024, 1025, 1026, 1027, 1029, 1032, 1033, 1034,\n",
       "       1038, 1037, 1044, 1043, 1042, 1135, 1136, 1138, 1137, 1141])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Correct misentered subject IDs with correct subject IDs from subject log\n",
    "realsubs = pd.read_csv('subjects.csv')\n",
    "\n",
    "realsubs['subjects'] = realsubs.subjects.apply(lambda x: str(x))\n",
    "out = out.loc[out.subjectID.isin(realsubs.subjects.tolist())]\n",
    "\n",
    "print(out.subjectID.unique())\n",
    "\n",
    "print('\\nTotal subjects:',len(out.subjectID.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove subjects that did not comply with EMA protocol, based on study notes\n",
    "out = out[out.subjectID != 1100]\n",
    "out = out[out.subjectID != 1101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1131 was kept in but only has 8 surveys\n"
     ]
    }
   ],
   "source": [
    "# Exclude subjects with less than 3 surveys & identify subjects with less than 20 surveys\n",
    "out['outlier_surveynum'] = 0\n",
    "for subject in out.subjectID.unique():\n",
    "    if len(out.loc[out.subjectID == subject]) < 3:\n",
    "        print(subject, 'was excluded for having ' + str(len(out[out.subjectID == subject])) + ' survey(s)')\n",
    "        out = out[out.subjectID != subject]\n",
    "    elif len(out[out.subjectID == subject]) < 20:\n",
    "        print(subject, 'was kept in but only has ' + str(len(out[out.subjectID == subject])) + ' surveys')\n",
    "        out.loc[out.subjectID == subject, 'outlier_surveynum'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1016 1011 1005 1017 1015 1007 1012 1020 1019 1022 1024 1026 1023 1025\n",
      " 1027 1029 1034 1033 1102 1032 1103 1104 1105 1038 1107 1037 1109 1044\n",
      " 1110 1043 1111 1042 1114 1116 1117 1120 1118 1122 1121 1125 1127 1128\n",
      " 1132 1126 1130 1131 1133 1136 1135 1138 1137 1141]\n",
      "\n",
      "Number of subjects:  52\n"
     ]
    }
   ],
   "source": [
    "# 52 subects remain\n",
    "print(out.subjectID.unique())\n",
    "print('\\nNumber of subjects: ', (out.subjectID.nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3837\n",
       "1      47\n",
       "Name: outlier_time, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify outliers based on time it took to complete the survey, to be excluded later\n",
    "out['outlier_time'] = 0\n",
    "out.loc[(out.duration < 30)|(out.duration > 86400),'outlier_time'] = 1\n",
    "\n",
    "out.outlier_time.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify and exclude unfinished surveys\n",
    "out.finished.value_counts()\n",
    "\n",
    "out = out.loc[(out.finished == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert variables to date format\n",
    "out['end_date'] = pd.to_datetime(out.end_date)\n",
    "out['start_date'] = pd.to_datetime(out.start_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create variable to identify the survey number based on time of day it was completed\n",
    "out['survey_number'] = 0\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for sub in out.subjectID.unique():\n",
    "    data = out[out.subjectID == sub]\n",
    "    data = data.sort_values(by = ['end_date'])\n",
    "    data = data.reset_index(drop=True)\n",
    "    for i, row_i in data.iterrows():\n",
    "        if i < 1:\n",
    "            data.loc[i, 'survey_number'] = 1\n",
    "        elif row_i.end_date.date() == data.loc[i - 1].end_date.date():\n",
    "            data.loc[i, 'survey_number'] = (data.loc[i - 1, 'survey_number'] + 1)\n",
    "        else:\n",
    "            data.loc[i, 'survey_number'] = 1\n",
    "    df = pd.concat([data, df])\n",
    "\n",
    "out = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verifying number of surveys\n",
    "out.survey_number.unique()\n",
    "out.survey_number.value_counts()\n",
    "out.loc[out.survey_number > 6][['subjectID','end_date','duration','survey_number']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove all surveys after survey 6\n",
    "out = out[out.survey_number < 7]\n",
    "out.survey_number.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subjectID</th>\n",
       "      <th>end_date</th>\n",
       "      <th>duration</th>\n",
       "      <th>survey_number</th>\n",
       "      <th>time_between</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1141</td>\n",
       "      <td>2019-05-01 10:07:43</td>\n",
       "      <td>288</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1141</td>\n",
       "      <td>2019-05-01 12:11:43</td>\n",
       "      <td>323</td>\n",
       "      <td>2</td>\n",
       "      <td>0 days 02:04:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1141</td>\n",
       "      <td>2019-05-01 14:04:34</td>\n",
       "      <td>228</td>\n",
       "      <td>3</td>\n",
       "      <td>0 days 01:52:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1141</td>\n",
       "      <td>2019-05-01 16:09:08</td>\n",
       "      <td>252</td>\n",
       "      <td>4</td>\n",
       "      <td>0 days 02:04:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1141</td>\n",
       "      <td>2019-05-01 18:05:18</td>\n",
       "      <td>265</td>\n",
       "      <td>5</td>\n",
       "      <td>0 days 01:56:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1141</td>\n",
       "      <td>2019-05-01 20:59:07</td>\n",
       "      <td>417</td>\n",
       "      <td>6</td>\n",
       "      <td>0 days 02:53:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1141</td>\n",
       "      <td>2019-05-02 14:34:20</td>\n",
       "      <td>1974</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1141</td>\n",
       "      <td>2019-05-03 10:18:14</td>\n",
       "      <td>975</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1141</td>\n",
       "      <td>2019-05-03 12:07:29</td>\n",
       "      <td>280</td>\n",
       "      <td>2</td>\n",
       "      <td>0 days 01:49:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1141</td>\n",
       "      <td>2019-05-03 15:52:15</td>\n",
       "      <td>6681</td>\n",
       "      <td>3</td>\n",
       "      <td>0 days 03:44:46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subjectID            end_date  duration  survey_number     time_between\n",
       "0       1141 2019-05-01 10:07:43       288              1              NaN\n",
       "1       1141 2019-05-01 12:11:43       323              2  0 days 02:04:00\n",
       "2       1141 2019-05-01 14:04:34       228              3  0 days 01:52:51\n",
       "3       1141 2019-05-01 16:09:08       252              4  0 days 02:04:34\n",
       "4       1141 2019-05-01 18:05:18       265              5  0 days 01:56:10\n",
       "5       1141 2019-05-01 20:59:07       417              6  0 days 02:53:49\n",
       "6       1141 2019-05-02 14:34:20      1974              1              NaN\n",
       "7       1141 2019-05-03 10:18:14       975              1              NaN\n",
       "8       1141 2019-05-03 12:07:29       280              2  0 days 01:49:15\n",
       "9       1141 2019-05-03 15:52:15      6681              3  0 days 03:44:46"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify time between each survey based on times they were completed\n",
    "df = pd.DataFrame()\n",
    "out['time_between'] = np.nan\n",
    "\n",
    "data = out\n",
    "data = data.reset_index(drop=True)\n",
    "for i, row_i in data.iterrows():\n",
    "    if row_i.survey_number == 1:\n",
    "        pass\n",
    "    else:\n",
    "        diff = row_i.end_date - (data.loc[i - 1, 'end_date'])\n",
    "        data.loc[i, 'time_between'] = diff\n",
    "\n",
    "data.time_between = data.time_between.apply(lambda x: np.nan if pd.isnull(x) else x.total_seconds()/3600)\n",
    "data[['subjectID','end_date','duration','survey_number','time_between']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag the survey as an outlier if the survey BEFORE it was completed less than 1 hour or greater than 3, for exclusion later on\n",
    "data['outlier_timebefore'] = 0\n",
    "data.loc[(data.time_between < 1)|(data.time_between >3), 'outlier_timebefore'] = 1\n",
    "\n",
    "print(data.outlier_timebefore.value_counts())\n",
    "\n",
    "print('\\nNumber of surveys with the previous one completed > 3 hours ago: '+ str(len(data.loc[(data.time_between > 3)])))\n",
    "print('\\nNumber of surveys with the previous one completed < 1 hour ago: '+ str(len(data.loc[(data.time_between < 1)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create day variable to show number of days since the start of EMA protocol\n",
    "df = pd.DataFrame()\n",
    "data['day'] = 0\n",
    "for sub in data.subjectID.unique():\n",
    "    tst_data = data[data.subjectID == sub]\n",
    "    tst_data = tst_data.sort_values(by = ['end_date'])\n",
    "    tst_data = tst_data.reset_index(drop=True)\n",
    "    for i, row_i in tst_data.iterrows():\n",
    "        if i < 1:\n",
    "            start = row_i.end_date.date()\n",
    "            tst_data.loc[i, 'day'] = 1\n",
    "        elif row_i.end_date.date() == start:\n",
    "            tst_data.loc[i, 'day'] = 1\n",
    "        else:\n",
    "            tst_data.loc[i, 'day'] = row_i.end_date.date() - start\n",
    "    df = pd.concat([tst_data, df])\n",
    "    \n",
    "df.day = df.day.apply(lambda x: x if isinstance(x, int) else x.total_seconds()/86400 + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PANAS positive and negative affect scores\n",
    "df['PA'] = df['enthusiastic_current'] + df['cheerful_current'] + df['relaxed_current']\n",
    "df['NA'] = df['irritable_current'] + df['anxious_current'] + df['sad_current']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new dataframe and add clinical group variable\n",
    "data = df\n",
    "data['group'] = 'CTL'\n",
    "data.loc[data.subjectID < 1100, 'group'] = 'MDD'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note on prediction error variables**  \n",
    "A PE is only calculated if...  \n",
    "1) a valid prediction was made within 1 - 3 hours prior and not first survey of the day),  \n",
    "2) the current survey was not a time outlier, and  \n",
    "3) the prior survey was not a time outlier  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subjectID</th>\n",
       "      <th>end_date</th>\n",
       "      <th>duration</th>\n",
       "      <th>survey_number</th>\n",
       "      <th>expected_value</th>\n",
       "      <th>expectation</th>\n",
       "      <th>actual_value</th>\n",
       "      <th>PE</th>\n",
       "      <th>expected_value_confidence</th>\n",
       "      <th>confidence_prev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1016</td>\n",
       "      <td>2017-11-14 08:15:09</td>\n",
       "      <td>271</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1016</td>\n",
       "      <td>2017-11-14 10:09:30</td>\n",
       "      <td>174</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1016</td>\n",
       "      <td>2017-11-14 12:25:29</td>\n",
       "      <td>147</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1016</td>\n",
       "      <td>2017-11-14 14:31:13</td>\n",
       "      <td>106</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1016</td>\n",
       "      <td>2017-11-14 17:58:04</td>\n",
       "      <td>205</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1016</td>\n",
       "      <td>2017-11-14 18:19:44</td>\n",
       "      <td>254</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1016</td>\n",
       "      <td>2017-11-16 08:32:46</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1016</td>\n",
       "      <td>2017-11-16 10:32:37</td>\n",
       "      <td>81</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1016</td>\n",
       "      <td>2017-11-16 12:21:55</td>\n",
       "      <td>281</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1016</td>\n",
       "      <td>2017-11-16 14:33:33</td>\n",
       "      <td>158</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subjectID            end_date  duration  survey_number  expected_value  \\\n",
       "0       1016 2017-11-14 08:15:09       271              1             2.0   \n",
       "1       1016 2017-11-14 10:09:30       174              2            -1.0   \n",
       "2       1016 2017-11-14 12:25:29       147              3             3.0   \n",
       "3       1016 2017-11-14 14:31:13       106              4             4.0   \n",
       "4       1016 2017-11-14 17:58:04       205              5             1.0   \n",
       "5       1016 2017-11-14 18:19:44       254              6             1.0   \n",
       "6       1016 2017-11-16 08:32:46       151              1             3.0   \n",
       "7       1016 2017-11-16 10:32:37        81              2             4.0   \n",
       "8       1016 2017-11-16 12:21:55       281              3             4.0   \n",
       "9       1016 2017-11-16 14:33:33       158              4             4.0   \n",
       "\n",
       "   expectation  actual_value   PE  expected_value_confidence  confidence_prev  \n",
       "0          NaN           2.0  NaN                       80.0              NaN  \n",
       "1          2.0           0.0 -2.0                       85.0             80.0  \n",
       "2         -1.0           0.0  1.0                       80.0             85.0  \n",
       "3          3.0           4.0  1.0                      100.0             80.0  \n",
       "4          4.0           2.0 -2.0                       80.0            100.0  \n",
       "5          1.0           2.0  1.0                       90.0             80.0  \n",
       "6          NaN           3.0  NaN                       80.0              NaN  \n",
       "7          3.0           4.0  1.0                      100.0             80.0  \n",
       "8          4.0           4.0  0.0                      100.0            100.0  \n",
       "9          4.0           NaN  NaN                      100.0            100.0  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create PE and expectation variables. Flag PE outliers based on number of surveys and time between.\n",
    "data['expectation'] = np.nan\n",
    "data['PE'] = np.nan\n",
    "data['PE_exclude'] = 0\n",
    "\n",
    "data = data.reset_index(drop=True)\n",
    "for i, row_i in data.iterrows():\n",
    "    if row_i.survey_number == 1: # can't get a PE for the first day\n",
    "        pass\n",
    "    else:\n",
    "        prev = data.loc[i - 1, 'expected_value'] # get the prediction from the previous row\n",
    "        data.loc[i, 'expectation'] = prev\n",
    "        if ((row_i.outlier_timebefore == 1) | (row_i.outlier_surveynum == 1) | (row_i.outlier_time ==1)):\n",
    "            data.loc[i, 'PE_exclude'] = 1\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "data['PE'] = data['actual_value'] - data['expectation'] # create a prediction error\n",
    "\n",
    "data[['subjectID','end_date','duration','survey_number','expected_value',\\\n",
    "      'actual_value', 'PE']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1038  was excluded for having 9 survey(s)\n",
      "1131  was excluded for having 3 survey(s)\n"
     ]
    }
   ],
   "source": [
    "# Remove subjects flagged for exclusion and store in a new, clean dataframe\n",
    "clean = data[data.PE_exclude == 0]\n",
    "\n",
    "for subject in clean.subjectID.unique():\n",
    "    if len(clean.loc[clean.subjectID == subject]) < 10:\n",
    "        print(subject, ' was excluded for having ' + str(len(clean[clean.subjectID == subject])) + ' survey(s)')\n",
    "        clean = clean[clean.subjectID != subject]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create absolute value, negative, and positive PE, EV, and AV variables.\n",
    "\n",
    "# Create PE_abs variable\n",
    "clean['PE_abs'] = clean.PE.abs()\n",
    "\n",
    "# Create negative PE\n",
    "clean['neg_PE'] = np.nan\n",
    "clean.loc[clean.PE < 0, 'neg_PE'] = clean.PE\n",
    "\n",
    "# Create positive PE\n",
    "clean['pos_PE'] = np.nan\n",
    "clean.loc[clean.PE > 0, 'pos_PE'] = clean.PE\n",
    "\n",
    "# Create frequencies of different PE types\n",
    "clean['pos_PE_freq'] = np.nan\n",
    "clean['neg_PE_freq'] = np.nan\n",
    "clean['no_PE_freq'] = np.nan\n",
    "for subject in clean.subjectID.unique():\n",
    "    sub_data = clean.loc[clean.subjectID == subject]\n",
    "    sub_data.reset_index(drop=True)\n",
    "    neg_PE = len(sub_data[sub_data.PE < 0])\n",
    "    pos_PE = len(sub_data[sub_data.PE > 0])\n",
    "    no_PE = len(sub_data[sub_data.PE == 0])\n",
    "    PE_tot = neg_PE + pos_PE + no_PE\n",
    "    clean.loc[clean.subjectID == subject, 'pos_PE_freq'] = pos_PE/PE_tot\n",
    "    clean.loc[clean.subjectID == subject, 'neg_PE_freq'] = neg_PE/PE_tot\n",
    "    clean.loc[clean.subjectID == subject, 'no_PE_freq'] = no_PE/PE_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create average PA, NA, and PE variables\n",
    "clean['average_PA'] = np.nan\n",
    "clean['average_NA'] = np.nan\n",
    "clean['average_PE'] = np.nan\n",
    "\n",
    "for sub in clean.subjectID.unique():\n",
    "    average_PE = clean[clean.subjectID == sub].PE.mean()\n",
    "    average_PA = clean[clean.subjectID == sub].PA.mean()\n",
    "    average_NA = clean[clean.subjectID == sub].NA.mean()\n",
    "    clean.loc[clean.subjectID==sub, 'average_PE'] = average_PE\n",
    "    clean.loc[clean.subjectID==sub, 'average_PA'] = average_PA\n",
    "    clean.loc[clean.subjectID==sub, 'average_NA'] = average_NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create frequency of negative, positive, and accurate/zero PE variables and assign them to a PE category\n",
    "clean['PE_category'] = ''\n",
    "clean['neg_PE_ct'] = 0\n",
    "clean['pos_PE_ct'] = 0\n",
    "clean['zero_PE_ct'] = 0\n",
    "\n",
    "for subject in clean.subjectID.unique():\n",
    "    sub_data = clean[clean.subjectID == subject]\n",
    "    \n",
    "    neg_ct = len(sub_data[sub_data.PE < 0])\n",
    "    pos_ct = len(sub_data[sub_data.PE > 0])\n",
    "    zero_ct = len(sub_data[sub_data.PE == 0])\n",
    "    \n",
    "    clean.loc[clean.subjectID == subject, 'pos_PE_ct'] = pos_ct\n",
    "    clean.loc[clean.subjectID == subject, 'neg_PE_ct'] = neg_ct\n",
    "    clean.loc[clean.subjectID == subject, 'zero_PE_ct'] = zero_ct\n",
    "    \n",
    "    if (neg_ct > pos_ct) & (neg_ct > zero_ct):\n",
    "        clean.loc[clean.subjectID == subject, 'PE_category'] = 'over'\n",
    "    elif (pos_ct > neg_ct) & (pos_ct > zero_ct):\n",
    "        clean.loc[clean.subjectID == subject, 'PE_category'] = 'under'\n",
    "    elif (zero_ct > pos_ct) & (zero_ct > neg_ct):\n",
    "        clean.loc[clean.subjectID == subject, 'PE_category'] = 'zero'\n",
    "    else:\n",
    "        print(str(subject) + ' has a tie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Normalize the positive and negative PEs by dividing by the number of accurate predictions (i.e. zero PE)\n",
    "clean['pos_zero_PE_diff'] = clean.pos_PE_ct/clean.zero_PE_ct\n",
    "clean['neg_zero_PE_diff'] = clean.neg_PE_ct/clean.zero_PE_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save final, clean data to file\n",
    "clean.to_csv(path2clean + 'EMA_Final.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
